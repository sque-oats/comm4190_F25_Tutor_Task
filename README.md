Testing LLMs as a Bike-Riding Tutor <br>

This repository explores how structured prompting can influence the behavior of a large language model (LLM) in simulating a tutoring session. The learning task for this project was riding a bike without training wheels. By comparing unstructured and structured tutoring sessions, this project examines how prompt design affects communication style, engagement, and instructional effectiveness. I used claude 3.5 as my LLM in all of my experiments. <br>

Contents:<br>
* README.md: Overview of my project and repo
* Session#1.json: Chatting with LLM using vague, short, and unstructered tutoring prompt.
* Session#2.json: Chatting with LLM using heavily structured tutoring prompt.
* Session#2.json: Chatting with LLM using heavily structured tutoring prompt with my modifications to the prompt.
* SessionsEvaluation.ipynb: My takeaways from the different sessions.
